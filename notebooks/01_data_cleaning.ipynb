{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392838c0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb50db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "from utils.data_cleaning_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1553eb",
   "metadata": {},
   "source": [
    "# Configuración de Datasets a leer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0fffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dicts= [\n",
    "    {\n",
    "        \"name\": \"australia\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\n",
    "            \"header\": [0,1]\n",
    "        },\n",
    "        \"final_name\" : \"australia_data\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cardiff\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"cardiff_data\"       \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"chile\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",\n",
    "            \"encoding\": \"latin1\",\n",
    "            \"usecols\": [\"IdEstablecimiento\", \"NEstablecimiento\", \"Total\", \"Menores_1\", \"De_1_a_4\", \"De_5_a_14\", \"De_15_a_64\", \"De_65_y_mas\", \"fecha\", \"semana\"]\n",
    "        },\n",
    "        \"final_name\" : \"chile_data\"    \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"colombia\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"colombia_data\"       \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"col_betania\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{   \n",
    "        },\n",
    "        \"final_name\" : \"colombia_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esp_canarias\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{   \n",
    "        },\n",
    "        \"final_name\" : \"spain_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esp_castilla_y_leon\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",\n",
    "            \"encoding\": \"utf-8-sig\"\n",
    "        },\n",
    "        \"final_name\" : \"spain_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"iowa\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "            \"header\": 3\n",
    "        },\n",
    "        \"final_name\" : \"usa_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"iran\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"iran_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2009\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None,\n",
    "            \"dtype\":{\n",
    "                2: str, 7: str, 13: str, 18: str, 19: str, 20: str, 21: str\n",
    "            }\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2010\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2011\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2012\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2013\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2014\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \";\",  \n",
    "            \"header\": None\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2015\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \",\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \",HORAINIATE\", \"MININIATE\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2016\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \",HORAINIATE\", \"MININIATE\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2017\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"encoding\": \"latin1\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \",HORAINIATE\", \"MININIATE\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2018\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \",\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \",HORAINIATE\", \"MININIATE\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2019\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \",\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \",HORAINIATE\", \"MININIATE\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2020\",\n",
    "        \"format\": \"txt\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"usecols\": [\"CLUES\", \"fechaingreso\", \"hora_ingreso\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2021\",\n",
    "        \"format\": \"txt\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"usecols\": [\"CLUES\", \"FECHAINGRESO\", \"HORA_INGRESO\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2022\",\n",
    "        \"format\": \"txt\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"usecols\": [\"CLUES\", \"fechaingreso\", \"hora_ingreso\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mexico_2023\",\n",
    "        \"format\": \"txt\",\n",
    "        \"options\":{\n",
    "            \"delimiter\": \"|\",\n",
    "            \"usecols\": [\"CLUES\", \"fechaingreso\", \"hora_ingreso\"]\n",
    "        },\n",
    "        \"final_name\" : \"mexico_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pak_\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"pakistan_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"usa_\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"usa_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"nl_\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"netherlands_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"bwa_\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"botswana_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"aus_\",\n",
    "        \"format\": \"xlsx\",\n",
    "        \"options\":{\n",
    "        },\n",
    "        \"final_name\" : \"australia_data\"   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"wales\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\":{\n",
    "            \"encoding\": \"latin1\",\n",
    "            \"skiprows\": 2\n",
    "        },\n",
    "        \"final_name\" : \"wales_data\"   \n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884d950",
   "metadata": {},
   "source": [
    "# Procesado de los Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e798892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo archivo: ../.gitignore/raw_datasets\\australia_data.csv\n",
      "DataFrame procesado con 3285 filas y 3 columnas.\n",
      "Archivo guardado exitosamente en: ../datasets/clean_datasets/australia_data.parquet\n",
      "Leyendo archivo: ../.gitignore/raw_datasets\\cardiff_1_data.csv\n",
      "DataFrame procesado con 43080 filas y 3 columnas.\n",
      "Archivo guardado exitosamente en: ../datasets/clean_datasets/cardiff_data.parquet\n",
      "Leyendo archivo: ../.gitignore/raw_datasets\\cardiff_2_data.csv\n",
      "DataFrame procesado con 43081 filas y 3 columnas.\n",
      "Archivo guardado exitosamente en: ../datasets/clean_datasets/cardiff_data.parquet\n",
      "Leyendo archivo: ../.gitignore/raw_datasets\\chile_2008_data.csv\n",
      "DataFrame procesado con 10574 filas y 3 columnas.\n",
      "Archivo guardado exitosamente en: ../datasets/clean_datasets/chile_data.parquet\n",
      "Leyendo archivo: ../.gitignore/raw_datasets\\chile_2009_data.csv\n",
      "DataFrame procesado con 55108 filas y 3 columnas.\n",
      "Archivo guardado exitosamente en: ../datasets/clean_datasets/chile_data.parquet\n",
      "Leyendo archivo: ../.gitignore/raw_datasets\\chile_2010_data.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     11\u001b[39m df_list = []\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m matching_files:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# if \"mexico_2021\" not in path:\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Se leen los datos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     df = \u001b[43mread_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     process_func_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprocess_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m     process_func = \u001b[38;5;28mglobals\u001b[39m().get(process_func_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\David\\Desktop\\UNI\\TFG\\Github\\TFG\\notebooks\\utils\\data_cleaning_utils.py:22\u001b[39m, in \u001b[36mread_raw_data\u001b[39m\u001b[34m(format, file_path, options)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m == \u001b[33m'\u001b[39m\u001b[33mcsv\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m options:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m         df = pd.read_csv(file_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "for dataset in datasets_dicts:\n",
    "    name = dataset[\"name\"]\n",
    "    format = dataset[\"format\"]\n",
    "    options = dataset[\"options\"]\n",
    "    final_name = dataset[\"final_name\"]\n",
    "\n",
    "    matching_files = read_multi_file_paths(format, name)\n",
    "    if not matching_files:\n",
    "        raise ValueError(f\"No matching files found for dataset '{name}'\")\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for path in matching_files:\n",
    "        # if \"mexico_2021\" not in path:\n",
    "        #     continue\n",
    "        # Se leen los datos\n",
    "        df = read_raw_data(format, path, options)\n",
    "        \n",
    "        process_func_name = f\"process_{name}\"\n",
    "        process_func = globals().get(process_func_name)\n",
    "\n",
    "        if process_func is None:\n",
    "            raise ValueError(f\"No se encontró la función '{process_func_name}'\")\n",
    "\n",
    "        # Procesado del DataFrame\n",
    "        processed_df = process_func(df)\n",
    "        \n",
    "        df_list.append(processed_df)\n",
    "        df_final = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        # Se guardan los datos procesados\n",
    "        save_clean_data(df_final, final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e92c58",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUES</th>\n",
       "      <th>FECHAINGRESO</th>\n",
       "      <th>HORA_INGRESO</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLSSA014295</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>10:01</td>\n",
       "      <td>2021-11-13 10:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLSSA014295</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>12:11</td>\n",
       "      <td>2021-02-11 12:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLSSA014295</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>99:99</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLSSA014295</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>99:99</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLSSA014295</td>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>99:99</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383300</th>\n",
       "      <td>DFSSA004084</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>18:08</td>\n",
       "      <td>2021-12-19 18:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383301</th>\n",
       "      <td>DFSSA004084</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>07:10</td>\n",
       "      <td>2021-12-06 07:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383302</th>\n",
       "      <td>DFSSA004084</td>\n",
       "      <td>2021-04-25</td>\n",
       "      <td>17:12</td>\n",
       "      <td>2021-04-25 17:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383303</th>\n",
       "      <td>DFSSA004084</td>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>08:50</td>\n",
       "      <td>2021-07-09 08:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383304</th>\n",
       "      <td>DFSSA004084</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>13:18</td>\n",
       "      <td>2021-08-23 13:18:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5383305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CLUES FECHAINGRESO HORA_INGRESO            datetime\n",
       "0        NLSSA014295   2021-11-13        10:01 2021-11-13 10:01:00\n",
       "1        NLSSA014295   2021-02-11        12:11 2021-02-11 12:11:00\n",
       "2        NLSSA014295   2021-09-25        99:99                 NaT\n",
       "3        NLSSA014295   2021-09-30        99:99                 NaT\n",
       "4        NLSSA014295   2021-11-23        99:99                 NaT\n",
       "...              ...          ...          ...                 ...\n",
       "5383300  DFSSA004084   2021-12-19        18:08 2021-12-19 18:08:00\n",
       "5383301  DFSSA004084   2021-12-06        07:10 2021-12-06 07:10:00\n",
       "5383302  DFSSA004084   2021-04-25        17:12 2021-04-25 17:12:00\n",
       "5383303  DFSSA004084   2021-07-09        08:50 2021-07-09 08:50:00\n",
       "5383304  DFSSA004084   2021-08-23        13:18 2021-08-23 13:18:00\n",
       "\n",
       "[5383305 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"FECHAINGRESO\"] = pd.to_datetime(df[\"FECHAINGRESO\"], errors=\"coerce\")\n",
    "\n",
    "# Crea columna 'datetime' combinando la fecha y la hora\n",
    "df[\"datetime\"] = pd.to_datetime(\n",
    "    df[\"FECHAINGRESO\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"HORA_INGRESO\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bce01",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['FECHAINGRESO', 'CLUES'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = df.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mfechaingreso\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mFECHAINGRESO\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_filtrado = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFECHAINGRESO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCLUES\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m df_filtrado.columns = [\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhospital\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m df_filtrado[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m] = df_filtrado[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['FECHAINGRESO', 'CLUES'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Se normalizan los nombres de las columnas\n",
    "# df.columns = df.columns.str.strip()\n",
    "\n",
    "# # Se filtran las filas que contienen datos numéricos en la columna \"Wales\" para evitar seleccionar los metadatos\n",
    "# df_filtrado = df[pd.to_numeric(df[\"Wales\"], errors=\"coerce\").notna()]\n",
    "\n",
    "# df_filtrado = df_filtrado.copy()\n",
    "\n",
    "# df_filtrado = df_filtrado.rename(columns={df_filtrado.columns[0]: \"Date\"})\n",
    "\n",
    "\n",
    "# df_filtrado[\"Date\"] = df_filtrado[\"Date\"].astype(str).str.strip().str.replace('\"', '')\n",
    "# df_filtrado = df_filtrado[df_filtrado[\"Date\"].str.match(r\"^\\d\")]\n",
    "\n",
    "# df_final = df_filtrado.melt(\n",
    "#     id_vars=[\"Date\"],                 \n",
    "#     value_vars=[col for col in df_filtrado.columns if col != \"Date\"],\n",
    "#     var_name=\"Hospital\",\n",
    "#     value_name=\"Admissions\"\n",
    "# )\n",
    "# df_final = df_final[df_final[\"Hospital\"] != \"Wales\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
